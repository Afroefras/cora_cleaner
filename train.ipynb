{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from random import randint\n",
    "import pytorch_lightning as pl\n",
    "from pydub import AudioSegment\n",
    "from scripts.extract import load_heart_noised_paths\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
    "from scripts.plot import plot_audio_sample, plot_prediction_from_dataset\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_noised = load_heart_noised_paths(\n",
    "    # clean_dir=\"data/heart_sound_test_small\",\n",
    "    # noised_dir=\"data/heart_noised_test_small\",\n",
    "    clean_dir=\"data/heart_sound\",\n",
    "    noised_dir=\"data/heart_noised\",\n",
    ")\n",
    "\n",
    "heart_noised[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo suena?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = heart_noised[randint(0, len(heart_noised))]\n",
    "\n",
    "audio_clean = AudioSegment.from_file(test[0])\n",
    "audio_noisy = AudioSegment.from_file(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo se ve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_array = np.array(audio_clean.get_array_of_samples())\n",
    "noisy_array = np.array(audio_noisy.get_array_of_samples())\n",
    "clean_array.shape, noisy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_sample(clean_array, \"Audio Limpio\")\n",
    "plot_audio_sample(noisy_array, \"Audio con Ruido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraDenoiserDataset(Dataset):\n",
    "    def __init__(self, data_tuples, transform=None, duration=None):\n",
    "        self.data_tuples = data_tuples\n",
    "        self.transform = transform\n",
    "        if duration is None:\n",
    "            self.min_duration = self.calculate_min_duration(level=10)\n",
    "        else:\n",
    "            self.min_duration = duration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_tuples)\n",
    "\n",
    "    def calculate_min_duration(self, level: int = 1):\n",
    "        self.durations = []\n",
    "        for _, audio_path in self.data_tuples:\n",
    "            audio, _ = torchaudio.load(audio_path)\n",
    "            self.durations.append(audio.shape[-1])\n",
    "\n",
    "        min_dur = min(self.durations) // level\n",
    "        return min_dur * level\n",
    "\n",
    "    def adjust_audio_duration(self, audio, duration):\n",
    "        if audio.shape[-1] > duration:\n",
    "            audio = audio[..., :duration]\n",
    "        return audio\n",
    "\n",
    "    def normalize_audio(self, audio):\n",
    "        normalized = (audio - audio.mean()) / audio.std()\n",
    "        return normalized\n",
    "\n",
    "    def preprocess_audio(self, idx, is_clean):\n",
    "        subidx = 0 if is_clean else 1\n",
    "        audio_path = self.data_tuples[idx][subidx]\n",
    "        audio, sample_rate = torchaudio.load(audio_path)\n",
    "        audio = self.adjust_audio_duration(audio, self.min_duration)\n",
    "        audio = self.normalize_audio(audio)\n",
    "        return audio, sample_rate\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean_audio, sample_rate = self.preprocess_audio(idx, is_clean=True)\n",
    "        noisy_audio, _ = self.preprocess_audio(idx, is_clean=False)\n",
    "\n",
    "        if self.transform:\n",
    "            clean_audio = self.transform(clean_audio, sample_rate)\n",
    "            noisy_audio = self.transform(noisy_audio, sample_rate)\n",
    "\n",
    "        return clean_audio, noisy_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.transform import spec_n_mfcc\n",
    "\n",
    "denoiser_dataset = CoraDenoiserDataset(\n",
    "    data_tuples=heart_noised,\n",
    "    transform=spec_n_mfcc,\n",
    "    duration=None\n",
    ")\n",
    "\n",
    "print(\"Pairs of sounds: \", len(denoiser_dataset))\n",
    "print(\"Min audio duration: \", denoiser_dataset.min_duration)\n",
    "denoiser_dataset[5][0].shape, denoiser_dataset[5][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = denoiser_dataset[5][0][..., :denoiser_dataset.min_duration]\n",
    "clean.shape, clean.mean(), clean.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy = denoiser_dataset[5][1][..., :denoiser_dataset.min_duration]\n",
    "noisy.shape, noisy.mean(), noisy.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DownConvBlock(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         input_size,\n",
    "#         output_size,\n",
    "#         kernel_size=3,\n",
    "#         stride=2,\n",
    "#         padding=1,\n",
    "#         norm=True,\n",
    "#         dropout=0.0,\n",
    "#     ):\n",
    "#         super(DownConvBlock, self).__init__()\n",
    "\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Conv1d(input_size, output_size, kernel_size, stride, padding),\n",
    "#             nn.BatchNorm1d(output_size) if norm else nn.Identity(),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout1d(dropout) if dropout else nn.Identity(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = self.layers(x)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# class UpConvBlock(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self, input_size, output_size, kernel_size=4, stride=2, padding=1, dropout=0.0\n",
    "#     ):\n",
    "#         super(UpConvBlock, self).__init__()\n",
    "\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.ConvTranspose1d(input_size, output_size, kernel_size, stride, padding),\n",
    "#             nn.BatchNorm1d(output_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout1d(dropout) if dropout else nn.Identity(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, encod_input):\n",
    "#         x = self.layers(x)\n",
    "#         output = torch.cat((x, encod_input), dim=1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CoraDenoiser(pl.LightningModule):\n",
    "#     def __init__(self, in_channels=1, out_channels=1):\n",
    "#         super().__init__()\n",
    "#         self.down_conv1 = DownConvBlock(in_channels, 16, norm=False)\n",
    "#         self.down_conv2 = DownConvBlock(16, 32)\n",
    "#         self.down_conv3 = DownConvBlock(32, 64)\n",
    "\n",
    "#         self.up_conv1 = UpConvBlock(64, 32, dropout=0.2)\n",
    "#         self.up_conv2 = UpConvBlock(64, 16, dropout=0.2)\n",
    "\n",
    "#         self.upsample = nn.Upsample(scale_factor=2)\n",
    "#         self.just_conv = nn.Conv1d(32, out_channels, kernel_size=1, padding=0)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         print(\"\\n\\nx\", x.shape)\n",
    "#         enc1 = self.down_conv1(x)\n",
    "#         print(\"enc1\", enc1.shape)\n",
    "#         enc2 = self.down_conv2(enc1)\n",
    "#         print(\"enc2\", enc2.shape)\n",
    "#         enc3 = self.down_conv3(enc2)\n",
    "#         print(\"enc3\", enc3.shape)\n",
    "\n",
    "#         dec1 = self.up_conv1(enc3, enc2)\n",
    "#         print(\"dec1\", dec1.shape)\n",
    "#         dec2 = self.up_conv2(dec1, enc1)\n",
    "#         print(\"dec2\", dec2.shape)\n",
    "\n",
    "#         upsample = self.upsample(dec2)\n",
    "#         print(\"upsample\", upsample.shape)\n",
    "#         final = self.just_conv(upsample)\n",
    "#         print(\"final\", final.shape, \"\\n\")\n",
    "        \n",
    "#         return final\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         clean, noisy = batch\n",
    "#         # Forward pass\n",
    "#         decoded = self(noisy)\n",
    "#         # Calculamos la pérdida (error de reconstrucción)\n",
    "#         train_loss = nn.MSELoss()(decoded, clean)\n",
    "#         # Registramos la pérdida para su monitoreo\n",
    "#         self.log(\"train_loss\", train_loss, on_epoch=True)\n",
    "\n",
    "#         return train_loss\n",
    "\n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         clean, noisy = batch\n",
    "#         decoded = self(noisy)\n",
    "#         val_loss = nn.MSELoss()(decoded, clean)\n",
    "#         self.log(\"val_loss\", val_loss, on_epoch=True)\n",
    "\n",
    "#         return val_loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "#         # optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#         # scheduler = {\n",
    "#         #     \"scheduler\": CyclicLR(\n",
    "#         #         optimizer, base_lr=0.001, max_lr=0.01, cycle_momentum=False\n",
    "#         #     ),\n",
    "#         #     \"interval\": \"step\",  # Frecuencia de ajuste del LR scheduler (en cada paso)\n",
    "#         # }\n",
    "\n",
    "#         # scheduler = {\n",
    "#         #     \"scheduler\": ReduceLROnPlateau(optimizer, patience=3),\n",
    "#         #     \"monitor\": \"val_loss\",  # Métrica para monitorear\n",
    "#         #     \"interval\": \"epoch\",    # Frecuencia de ajuste del LR scheduler\n",
    "#         #     \"frequency\": 1          # Igual a interval, ya que estamos usando \"epoch\"\n",
    "#         # }\n",
    "\n",
    "#         # return [optimizer], [scheduler]\n",
    "#         return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoraDenoiser(pl.LightningModule):\n",
    "    def __init__(self, input_length, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_length, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_length),x\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print('x', x.shape)\n",
    "        latent_code = self.encoder(x)\n",
    "        # print('latent_code', latent_code.shape)\n",
    "        reconstructed = self.decoder(latent_code)\n",
    "        # print('reconstructed', reconstructed.shape)\n",
    "        return reconstructed\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        clean, noisy = batch\n",
    "        # Forward pass\n",
    "        decoded = self(noisy)\n",
    "        # Calculamos la pérdida (error de reconstrucción)\n",
    "        train_loss = nn.MSELoss()(decoded, clean)\n",
    "        # Registramos la pérdida para su monitoreo\n",
    "        self.log(\"train_loss\", train_loss, on_epoch=True)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        clean, noisy = batch\n",
    "        decoded = self(noisy)\n",
    "        val_loss = nn.MSELoss()(decoded, clean)\n",
    "        self.log(\"val_loss\", val_loss, on_epoch=True)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "train_size = int(train_ratio * len(denoiser_dataset))\n",
    "val_size = int(val_ratio * len(denoiser_dataset))\n",
    "test_size = len(denoiser_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    denoiser_dataset, [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"autoencoder-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# callbacks = [checkpoint, lr_monitor]\n",
    "callbacks = [checkpoint, early_stopping, lr_monitor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoraDenoiser(\n",
    "    input_length=denoiser_dataset[0][0].shape[-1],\n",
    "    latent_dim=64\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"logs/\", name=\"cora_cleaner\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, callbacks=callbacks, logger=logger)\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_from_dataset(\n",
    "    model=model,\n",
    "    dataset=denoiser_dataset,\n",
    "    duration=denoiser_dataset.min_duration,\n",
    "    idx=randint(0, len(denoiser_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar para revisar el Tensorboard en web\n",
    "# !tensorboard --logdir=path_to_logs_directory\n",
    "\n",
    "# Otra opción es VisualStudioCode: Ctrl+Shift+P -> Launch Tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cora_cleaner-eXlQ0b7N",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
